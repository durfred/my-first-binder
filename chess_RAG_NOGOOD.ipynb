{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPJqcEi/Cu5qebKq1jYClR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/durfred/my-first-binder/blob/main/chess_RAG_NOGOOD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yllwc0mX4qto",
        "outputId": "bf44b034-48aa-4148-d9e1-8d422f666766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Ê∏ÖÁêÜÊóßÊñá‰ª∂ ---\n",
            "\n",
            "--- ‰∏ãËΩΩÂπ∂Ëß£ÂéãÊ£ãË∞±Êï∞ÊçÆ ---\n",
            "--2025-06-26 19:37:39--  https://www.pgnmentor.com/players/Carlsen.zip\n",
            "Resolving www.pgnmentor.com (www.pgnmentor.com)... 65.254.227.240\n",
            "Connecting to www.pgnmentor.com (www.pgnmentor.com)|65.254.227.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1553745 (1.5M) [application/zip]\n",
            "Saving to: ‚Äò/content/Carlsen.zip‚Äô\n",
            "\n",
            "/content/Carlsen.zi 100%[===================>]   1.48M  2.94MB/s    in 0.5s    \n",
            "\n",
            "2025-06-26 19:37:40 (2.94 MB/s) - ‚Äò/content/Carlsen.zip‚Äô saved [1553745/1553745]\n",
            "\n",
            "Archive:  /content/Carlsen.zip\n",
            "  inflating: /content/Carlsen/Carlsen.pgn  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# ËÆæÁΩÆË∑ØÂæÑ\n",
        "CARLSEN_DATA_DIR = \"/content/Carlsen\"\n",
        "CARLSEN_ZIP_FILENAME = \"/content/Carlsen.zip\"\n",
        "PGN_FILE = f\"{CARLSEN_DATA_DIR}/Carlsen.pgn\"  # Ëß£ÂéãÂêéÊü•ÁúãÂÆûÈôÖÊñá‰ª∂Âêç\n",
        "\n",
        "# --- 1. Ê∏ÖÁêÜÊóßÊñá‰ª∂ ---\n",
        "print(\"\\n--- Ê∏ÖÁêÜÊóßÊñá‰ª∂ ---\")\n",
        "shutil.rmtree(CARLSEN_DATA_DIR, ignore_errors=True)\n",
        "if os.path.exists(CARLSEN_ZIP_FILENAME): os.remove(CARLSEN_ZIP_FILENAME)\n",
        "\n",
        "# --- 2. ‰∏ãËΩΩÂπ∂Ëß£Âéã Carlsen ÂõΩÈôÖË±°Ê£ãÊï∞ÊçÆ ---\n",
        "print(\"\\n--- ‰∏ãËΩΩÂπ∂Ëß£ÂéãÊ£ãË∞±Êï∞ÊçÆ ---\")\n",
        "os.makedirs(CARLSEN_DATA_DIR, exist_ok=True)\n",
        "!wget -O {CARLSEN_ZIP_FILENAME} https://www.pgnmentor.com/players/Carlsen.zip\n",
        "!unzip -o {CARLSEN_ZIP_FILENAME} -d {CARLSEN_DATA_DIR}\n",
        "os.remove(CARLSEN_ZIP_FILENAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-chess llama-cpp-python --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f6nQ-ug5RP8",
        "outputId": "5fd848e4-f114-48de-f8ad-48452e255495"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-chess\n",
            "  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.9.tar.gz (67.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting chess<2,>=1 (from python-chess)\n",
            "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (2.0.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python, chess\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.9-cp311-cp311-linux_x86_64.whl size=4067781 sha256=c16521c0e2b5b75a6979212abfd15106a84571dfc1c574f54e8dca78fd0c3b61\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/8f/bf/148c8eb7d69021eccd6eae6444f3accd48347587054ffd24e5\n",
            "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=b98679185fee58807bb4f35233ac0a048e940d6874ef23474676887ca997e774\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\n",
            "Successfully built llama-cpp-python chess\n",
            "Installing collected packages: diskcache, chess, python-chess, llama-cpp-python\n",
            "Successfully installed chess-1.11.2 diskcache-5.6.3 llama-cpp-python-0.3.9 python-chess-1.999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chess.pgn\n",
        "\n",
        "def extract_fens_and_moves_from_pgn(pgn_file, max_games=1000):\n",
        "    fens = []\n",
        "    moves = []\n",
        "\n",
        "    with open(pgn_file) as f:\n",
        "        game_count = 0\n",
        "        while game_count < max_games:\n",
        "            game = chess.pgn.read_game(f)\n",
        "            if game is None:\n",
        "                break\n",
        "\n",
        "            board = game.board()\n",
        "            for move in game.mainline_moves():\n",
        "                fens.append(board.fen())\n",
        "                moves.append(board.san(move))\n",
        "                board.push(move)\n",
        "\n",
        "            game_count += 1\n",
        "    return fens, moves\n",
        "\n",
        "fens, moves = extract_fens_and_moves_from_pgn(PGN_FILE)\n",
        "print(\"ÊÄªÂÖ±ÊèêÂèñÊ£ãÁõòÁä∂ÊÄÅ:\", len(fens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjgjzNH14uLl",
        "outputId": "c7463013-c481-4978-9a8a-5fc8814f0d17"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÊÄªÂÖ±ÊèêÂèñÊ£ãÁõòÁä∂ÊÄÅ: 86861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvdAa4w57dTY",
        "outputId": "7ba567ea-2aea-4b3f-c5fe-a87b10087350"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "def hash_fen(fen):\n",
        "    return np.array([[hash(fen) % 1_000_000]], dtype='float32')  # shape=(1, 1)\n",
        "\n",
        "index = faiss.IndexFlatL2(1)\n",
        "for fen in fens:\n",
        "    index.add(hash_fen(fen))\n",
        "\n",
        "move_dict = dict(zip(range(len(moves)), moves))\n"
      ],
      "metadata": {
        "id": "Hk09amwv7Tuh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_move_by_rag(current_fen):\n",
        "    query = hash_fen(current_fen)\n",
        "    D, I = index.search(query, 1)\n",
        "    return move_dict[I[0][0]]\n",
        "\n"
      ],
      "metadata": {
        "id": "0st3tNoB7x0x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chess.pgn\n",
        "\n",
        "def extract_fens_and_moves_from_pgn(pgn_file, max_games=1000):\n",
        "    fens = []\n",
        "    moves = []\n",
        "\n",
        "    with open(pgn_file) as f:\n",
        "        game_count = 0\n",
        "        while game_count < max_games:\n",
        "            game = chess.pgn.read_game(f)\n",
        "            if game is None:\n",
        "                break\n",
        "\n",
        "            board = game.board()\n",
        "            for move in game.mainline_moves():\n",
        "                fens.append(board.fen())\n",
        "                moves.append(board.san(move))\n",
        "                board.push(move)\n",
        "\n",
        "            game_count += 1\n",
        "    return fens, moves\n"
      ],
      "metadata": {
        "id": "3eeJUxfB78bv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/codegood/gemma-2b-it-Q4_K_M-GGUF/resolve/main/gemma-2b-it.Q4_K_M.gguf"
      ],
      "metadata": {
        "id": "_7dVmW8d8LFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316da752-07dd-4759-982a-9aa002d5c566"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-26 19:49:00--  https://huggingface.co/codegood/gemma-2b-it-Q4_K_M-GGUF/resolve/main/gemma-2b-it.Q4_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 3.168.73.38, 3.168.73.111, 3.168.73.129, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.168.73.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/2e/3e/2e3e8837d8e4731552352bf441fc9458f6d4be48b3923aa2ea48e2107e8762bd/509635a3ad10c9d73a282e461ddb4415b68cbf2ce2f2c02cd0657cf933370d1a?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27gemma-2b-it.Q4_K_M.gguf%3B+filename%3D%22gemma-2b-it.Q4_K_M.gguf%22%3B&Expires=1750970940&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDk3MDk0MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzJlLzNlLzJlM2U4ODM3ZDhlNDczMTU1MjM1MmJmNDQxZmM5NDU4ZjZkNGJlNDhiMzkyM2FhMmVhNDhlMjEwN2U4NzYyYmQvNTA5NjM1YTNhZDEwYzlkNzNhMjgyZTQ2MWRkYjQ0MTViNjhjYmYyY2UyZjJjMDJjZDA2NTdjZjkzMzM3MGQxYT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=toqgFgoFNOKUyWEJXT1lCesuAJKnJ-iFoA-V2Eb-V8rqYd7A9JvfcctuDNZQndWMFuTuz2duWevbG1roYQwH6EAGe-2FHPGV7CwjuZt5n-Fn8IQzuIRstkKxPgd4yIRL2YWgaLcgSUKu9Z6hgY-bqhl%7ELNjb01s9zC4LI15l3jHLbiL3kCFacMKhdxRzD0usAirr75N5mUVH3c7HQhEd1ZTI7QvhlenYPzEWZ3QtwEuuKdq7mrb1s8siVANDpV2lOdvwXGjjtOvEKTc9FILm9BjrcSXUev2sNL%7ET8mruaqxgfdFZV9v7v0qU6MBm0Ifklbs2hWB%7Ech%7EGikQ9hAklcw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-06-26 19:49:00--  https://cdn-lfs-us-1.hf.co/repos/2e/3e/2e3e8837d8e4731552352bf441fc9458f6d4be48b3923aa2ea48e2107e8762bd/509635a3ad10c9d73a282e461ddb4415b68cbf2ce2f2c02cd0657cf933370d1a?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27gemma-2b-it.Q4_K_M.gguf%3B+filename%3D%22gemma-2b-it.Q4_K_M.gguf%22%3B&Expires=1750970940&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDk3MDk0MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzJlLzNlLzJlM2U4ODM3ZDhlNDczMTU1MjM1MmJmNDQxZmM5NDU4ZjZkNGJlNDhiMzkyM2FhMmVhNDhlMjEwN2U4NzYyYmQvNTA5NjM1YTNhZDEwYzlkNzNhMjgyZTQ2MWRkYjQ0MTViNjhjYmYyY2UyZjJjMDJjZDA2NTdjZjkzMzM3MGQxYT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=toqgFgoFNOKUyWEJXT1lCesuAJKnJ-iFoA-V2Eb-V8rqYd7A9JvfcctuDNZQndWMFuTuz2duWevbG1roYQwH6EAGe-2FHPGV7CwjuZt5n-Fn8IQzuIRstkKxPgd4yIRL2YWgaLcgSUKu9Z6hgY-bqhl%7ELNjb01s9zC4LI15l3jHLbiL3kCFacMKhdxRzD0usAirr75N5mUVH3c7HQhEd1ZTI7QvhlenYPzEWZ3QtwEuuKdq7mrb1s8siVANDpV2lOdvwXGjjtOvEKTc9FILm9BjrcSXUev2sNL%7ET8mruaqxgfdFZV9v7v0qU6MBm0Ifklbs2hWB%7Ech%7EGikQ9hAklcw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 108.139.47.100, 108.139.47.127, 108.139.47.7, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|108.139.47.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1630263008 (1.5G) [binary/octet-stream]\n",
            "Saving to: ‚Äògemma-2b-it.Q4_K_M.gguf‚Äô\n",
            "\n",
            "gemma-2b-it.Q4_K_M. 100%[===================>]   1.52G   199MB/s    in 7.2s    \n",
            "\n",
            "2025-06-26 19:49:07 (217 MB/s) - ‚Äògemma-2b-it.Q4_K_M.gguf‚Äô saved [1630263008/1630263008]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=\"gemma-2b-it.Q4_K_M.gguf\",\n",
        "    n_ctx=2048,\n",
        "    n_threads=8  # Increased threads\n",
        ")\n",
        "\n",
        "def get_move_from_llm(prompt):\n",
        "    output = llm(prompt, max_tokens=128) # Increased max_tokens\n",
        "    return output[\"choices\"][0][\"text\"].strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8LdpRGw8FVO",
        "outputId": "b4c865d2-6f91-41e2-c521-65a82e9bf914"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 24 key-value pairs and 164 tensors from gemma-2b-it.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gemma\n",
            "llama_model_loader: - kv   1:                               general.name str              = gemma-2b-it\n",
            "llama_model_loader: - kv   2:                       gemma.context_length u32              = 8192\n",
            "llama_model_loader: - kv   3:                     gemma.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   4:                          gemma.block_count u32              = 18\n",
            "llama_model_loader: - kv   5:                  gemma.feed_forward_length u32              = 16384\n",
            "llama_model_loader: - kv   6:                 gemma.attention.head_count u32              = 8\n",
            "llama_model_loader: - kv   7:              gemma.attention.head_count_kv u32              = 1\n",
            "llama_model_loader: - kv   8:     gemma.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv   9:                 gemma.attention.key_length u32              = 256\n",
            "llama_model_loader: - kv  10:               gemma.attention.value_length u32              = 256\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,256000]  = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 1\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 3\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% if messages[0]['rol...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   37 tensors\n",
            "llama_model_loader: - type q4_K:  108 tensors\n",
            "llama_model_loader: - type q6_K:   19 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 1.51 GiB (5.18 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 1\n",
            "load: control-looking token:    107 '<end_of_turn>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
            "load: control token:      2 '<bos>' is not marked as EOG\n",
            "load: control token:      0 '<pad>' is not marked as EOG\n",
            "load: control token:      1 '<eos>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 5\n",
            "load: token to piece cache size = 1.6014 MB\n",
            "print_info: arch             = gemma\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 8192\n",
            "print_info: n_embd           = 2048\n",
            "print_info: n_layer          = 18\n",
            "print_info: n_head           = 8\n",
            "print_info: n_head_kv        = 1\n",
            "print_info: n_rot            = 256\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_swa_pattern    = 1\n",
            "print_info: n_embd_head_k    = 256\n",
            "print_info: n_embd_head_v    = 256\n",
            "print_info: n_gqa            = 8\n",
            "print_info: n_embd_k_gqa     = 256\n",
            "print_info: n_embd_v_gqa     = 256\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-06\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 16384\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 2\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 10000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 8192\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 2B\n",
            "print_info: model params     = 2.51 B\n",
            "print_info: general.name     = gemma-2b-it\n",
            "print_info: vocab type       = SPM\n",
            "print_info: n_vocab          = 256000\n",
            "print_info: n_merges         = 0\n",
            "print_info: BOS token        = 2 '<bos>'\n",
            "print_info: EOS token        = 1 '<eos>'\n",
            "print_info: EOT token        = 107 '<end_of_turn>'\n",
            "print_info: UNK token        = 3 '<unk>'\n",
            "print_info: PAD token        = 0 '<pad>'\n",
            "print_info: LF token         = 227 '<0x0A>'\n",
            "print_info: EOG token        = 1 '<eos>'\n",
            "print_info: EOG token        = 107 '<end_of_turn>'\n",
            "print_info: max token length = 93\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q6_K) (and 56 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:  CPU_AARCH64 model buffer size =   898.59 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =  1548.98 MiB\n",
            "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
            "...........\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 2048\n",
            "llama_context: n_ctx_per_seq = 2048\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: freq_base     = 10000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (2048) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:        CPU  output buffer size =     0.98 MiB\n",
            "create_memory: n_ctx = 2048 (padded)\n",
            "llama_kv_cache_unified: kv_size = 2048, type_k = 'f16', type_v = 'f16', n_layer = 18, can_shift = 1, padding = 32\n",
            "llama_kv_cache_unified: layer   0: dev = CPU\n",
            "llama_kv_cache_unified: layer   1: dev = CPU\n",
            "llama_kv_cache_unified: layer   2: dev = CPU\n",
            "llama_kv_cache_unified: layer   3: dev = CPU\n",
            "llama_kv_cache_unified: layer   4: dev = CPU\n",
            "llama_kv_cache_unified: layer   5: dev = CPU\n",
            "llama_kv_cache_unified: layer   6: dev = CPU\n",
            "llama_kv_cache_unified: layer   7: dev = CPU\n",
            "llama_kv_cache_unified: layer   8: dev = CPU\n",
            "llama_kv_cache_unified: layer   9: dev = CPU\n",
            "llama_kv_cache_unified: layer  10: dev = CPU\n",
            "llama_kv_cache_unified: layer  11: dev = CPU\n",
            "llama_kv_cache_unified: layer  12: dev = CPU\n",
            "llama_kv_cache_unified: layer  13: dev = CPU\n",
            "llama_kv_cache_unified: layer  14: dev = CPU\n",
            "llama_kv_cache_unified: layer  15: dev = CPU\n",
            "llama_kv_cache_unified: layer  16: dev = CPU\n",
            "llama_kv_cache_unified: layer  17: dev = CPU\n",
            "llama_kv_cache_unified:        CPU KV buffer size =    36.00 MiB\n",
            "llama_kv_cache_unified: KV self size  =   36.00 MiB, K (f16):   18.00 MiB, V (f16):   18.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 1\n",
            "llama_context: max_nodes = 65536\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
            "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
            "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
            "llama_context:        CPU compute buffer size =   504.00 MiB\n",
            "llama_context: graph nodes  = 637\n",
            "llama_context: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\\n' + message['content'] | trim + '<end_of_turn>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '3', 'tokenizer.ggml.eos_token_id': '1', 'tokenizer.ggml.bos_token_id': '2', 'general.architecture': 'gemma', 'gemma.feed_forward_length': '16384', 'tokenizer.ggml.add_bos_token': 'true', 'gemma.attention.head_count': '8', 'general.name': 'gemma-2b-it', 'gemma.context_length': '8192', 'gemma.embedding_length': '2048', 'gemma.block_count': '18', 'gemma.attention.head_count_kv': '1', 'gemma.attention.key_length': '256', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'gemma.attention.layer_norm_rms_epsilon': '0.000001', 'gemma.attention.value_length': '256', 'general.file_type': '15'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Using gguf chat template: {{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n",
            "' + message['content'] | trim + '<end_of_turn>\n",
            "' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n",
            "'}}{% endif %}\n",
            "Using chat eos_token: <eos>\n",
            "Using chat bos_token: <bos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "import random # Import random for selecting a legal move if needed\n",
        "\n",
        "def build_prompt_with_history(board, historical_move):\n",
        "    fen = board.fen()\n",
        "\n",
        "    # ÊûÑÂª∫‰∫∫Á±ªÈ£éÊ†ºÊ£ãË∞±ÂéÜÂè≤ÔºàSAN Ê†ºÂºèÔºåÂ¶Ç 1. e4 c5Ôºâ\n",
        "    move_history = []\n",
        "    temp_board = chess.Board()\n",
        "    for move in board.move_stack:\n",
        "        move_history.append(temp_board.san(move))\n",
        "        temp_board.push(move)\n",
        "\n",
        "    numbered_history = \"\"\n",
        "    for i in range(0, len(move_history), 2):\n",
        "        turn = i // 2 + 1\n",
        "        white = move_history[i]\n",
        "        black = move_history[i+1] if i + 1 < len(move_history) else \"\"\n",
        "        numbered_history += f\"{turn}. {white} {black} \"\n",
        "\n",
        "    # Get legal moves in long algebraic notation\n",
        "    legal_moves_uci = [move.uci() for move in board.legal_moves]\n",
        "    legal_moves_str = \", \".join(legal_moves_uci)\n",
        "\n",
        "\n",
        "    return f\"\"\"You are a chess AI assistant.\n",
        "\n",
        "Game so far:\n",
        "{numbered_history.strip()}\n",
        "\n",
        "Current board position (FEN):\n",
        "{fen}\n",
        "\n",
        "A similar historical move was: {historical_move}\n",
        "\n",
        "It is {'White' if board.turn else 'Black'} to play.\n",
        "\n",
        "The legal moves in this position are: {legal_moves_str}\n",
        "\n",
        "Please respond with ONLY the next legal move from the list provided above in **long algebraic notation** like \"e2e4\", \"g1f3\", or \"c1d3\".\n",
        "\n",
        "Do NOT explain. Only output the move.\n",
        "\n",
        "Move:\"\"\"\n",
        "\n",
        "# ÂàùÂßãÂåñÊ£ãÁõò\n",
        "board = chess.Board()\n",
        "\n",
        "# ‰∏ªÂæ™ÁéØÔºöÁé©ÂÆ∂ vs AI\n",
        "while not board.is_game_over():\n",
        "    print(\"\\nÂΩìÂâçÊ£ãÁõò:\")\n",
        "    print(board)\n",
        "\n",
        "    # Áé©ÂÆ∂Ëµ∞Ê£ã\n",
        "    try:\n",
        "        player_move = input(\"\\n‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): \").strip()\n",
        "        move = chess.Move.from_uci(player_move)\n",
        "        if move in board.legal_moves:\n",
        "            board.push(move)\n",
        "        else:\n",
        "            print(\"‚ùå ÈùûÊ≥ïËµ∞Ê≥ï:\", player_move)\n",
        "            continue\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå ËæìÂÖ•ÈîôËØØ:\", e)\n",
        "        continue\n",
        "\n",
        "    # Check if game is over after player's move\n",
        "    if board.is_game_over():\n",
        "        print(\"üèÅ Ê∏∏ÊàèÁªìÊùüÔºÅ\")\n",
        "        break\n",
        "\n",
        "    # AI Ëµ∞Ê£ã\n",
        "    fen = board.fen()\n",
        "    query = hash_fen(fen)\n",
        "    _, I = index.search(query, 1)\n",
        "    historical_move = move_dict[I[0][0]]\n",
        "\n",
        "    # Get AI suggestion\n",
        "    prompt = build_prompt_with_history(board, historical_move)\n",
        "    suggestion = get_move_from_llm(prompt).strip().split()[0]\n",
        "    print(\"\\nü§ñ AIÂª∫ËÆÆËµ∞Ê≥ï:\", suggestion)\n",
        "\n",
        "    # Validate AI move and push if legal, otherwise pick a random legal move\n",
        "    try:\n",
        "        ai_move = chess.Move.from_uci(suggestion)\n",
        "        if ai_move in board.legal_moves:\n",
        "            board.push(ai_move)\n",
        "        else:\n",
        "            print(\"‚ùå AI Âª∫ËÆÆÈùûÊ≥ïËµ∞Ê≥ï:\", suggestion, \". Choosing a random legal move.\")\n",
        "            legal_moves = list(board.legal_moves)\n",
        "            if legal_moves:\n",
        "                chosen_move = random.choice(legal_moves)\n",
        "                print(f\"ü§ñ AI makes legal move: {chosen_move.uci()}\")\n",
        "                board.push(chosen_move)\n",
        "            else:\n",
        "                print(\"ü§∑ No legal moves available for AI.\")\n",
        "                break # Should not happen in a standard game\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå AI ËæìÂá∫Ê†ºÂºèÈîôËØØ:\", suggestion, \"| ÈîôËØØ:\", e, \". Choosing a random legal move.\")\n",
        "        legal_moves = list(board.legal_moves)\n",
        "        if legal_moves:\n",
        "            chosen_move = random.choice(legal_moves)\n",
        "            print(f\"ü§ñ AI makes legal move: {chosen_move.uci()}\")\n",
        "            board.push(chosen_move)\n",
        "        else:\n",
        "            print(\"ü§∑ No legal moves available for AI.\")\n",
        "            break # Should not happen in a standard game\n",
        "\n",
        "\n",
        "# Ê∏∏ÊàèÁªìÊùü\n",
        "print(\"\\nüèÅ Ê∏∏ÊàèÁªìÊùüÔºÅÁªìÊûú:\", board.result())\n",
        "print(board)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "zoqYuV449bBG",
        "outputId": "4272dea7-c5c6-44ce-c874-81d95130a245"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            "P P P P P P P P\n",
            "R N B Q K B N R\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): d2d4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 16 prefix-match hit, remaining 226 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   20660.81 ms\n",
            "llama_perf_context_print: prompt eval time =   73521.29 ms /   227 tokens (  323.88 ms per token,     3.09 tokens per second)\n",
            "llama_perf_context_print:        eval time =     826.33 ms /     4 runs   (  206.58 ms per token,     4.84 tokens per second)\n",
            "llama_perf_context_print:       total time =   20023.94 ms /   231 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ AIÂª∫ËÆÆËµ∞Ê≥ï: e2e4\n",
            "‚ùå AI Âª∫ËÆÆÈùûÊ≥ïËµ∞Ê≥ï: e2e4 . Choosing a random legal move.\n",
            "ü§ñ AI makes legal move: g7g5\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b n r\n",
            "p p p p p p . p\n",
            ". . . . . . . .\n",
            ". . . . . . p .\n",
            ". . . P . . . .\n",
            ". . . . . . . .\n",
            "P P P . P P P P\n",
            "R N B Q K B N R\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-25-1808368588.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Áé©ÂÆ∂Ëµ∞Ê£ã\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mplayer_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_uci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer_move\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegal_moves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GF0WYqqLyd7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be656a85"
      },
      "source": [
        "# Task\n",
        "Improve the chess AI's ability to select legal and strategic moves by analyzing RAG effectiveness, improving prompt engineering, exploring alternative LLM strategies, implementing basic evaluation, and refining the AI move selection logic. Playtest and iterate on the improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ef634d"
      },
      "source": [
        "## Analyze rag effectiveness\n",
        "\n",
        "### Subtask:\n",
        "Evaluate if the current RAG approach (hashing FENs) is providing relevant historical moves. Consider alternative embedding methods for chess positions if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a34813ff"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the effectiveness of the current RAG approach by selecting a few FENs, hashing them, searching the index, retrieving the associated historical move, and manually inspecting the relevance of the suggested move.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "126f4f52",
        "outputId": "55037dff-dd34-410c-f1fc-7f1720698a70"
      },
      "source": [
        "import chess\n",
        "\n",
        "# Select a few diverse FENs from the list\n",
        "selected_fens = [\n",
        "    fens[0],       # Start of the game\n",
        "    fens[100],     # Early game\n",
        "    fens[1000],    # Mid game\n",
        "    fens[10000],   # Later game\n",
        "    fens[-1]       # End game (could be checkmate, draw, etc.)\n",
        "]\n",
        "\n",
        "print(\"--- Evaluating RAG Effectiveness ---\")\n",
        "\n",
        "for original_fen in selected_fens:\n",
        "    print(f\"\\nOriginal FEN: {original_fen}\")\n",
        "\n",
        "    # Get hash and search index\n",
        "    query = hash_fen(original_fen)\n",
        "    D, I = index.search(query, 1)\n",
        "    historical_index = I[0][0]\n",
        "\n",
        "    # Retrieve historical move\n",
        "    suggested_historical_move = move_dict[historical_index]\n",
        "\n",
        "    # Note: Retrieving the historical FEN directly from the index using the index\n",
        "    # is not straightforward with this simple hashing method and FAISS index.\n",
        "    # We are only storing the index of the move.\n",
        "    # For a more robust evaluation of the matched FEN, we would need to store\n",
        "    # the FENs in the order they were added or use a different indexing method.\n",
        "    # For now, we will focus on the suggested move's relevance.\n",
        "\n",
        "    print(f\"Index of closest historical FEN: {historical_index}\")\n",
        "    print(f\"Suggested historical move: {suggested_historical_move}\")\n",
        "\n",
        "    # Manual Inspection Guidance:\n",
        "    # Look at the Original FEN and the Suggested historical move.\n",
        "    # Does this move make sense in the context of the original FEN board state?\n",
        "    # With the current simple hashing, collisions are highly likely,\n",
        "    # so the suggested move might be from a completely unrelated position.\n",
        "    # This manual check helps confirm if the hashing method is effective\n",
        "    # at finding truly *similar* historical positions.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluating RAG Effectiveness ---\n",
            "\n",
            "Original FEN: rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
            "Index of closest historical FEN: 0\n",
            "Suggested historical move: d4\n",
            "\n",
            "Original FEN: 2r2bk1/4nppp/4p3/p2pP3/n1r4P/PRP1B1P1/2N2P2/RN3K2 w - - 4 28\n",
            "Index of closest historical FEN: 100\n",
            "Suggested historical move: Bd4\n",
            "\n",
            "Original FEN: 2r5/p1p1Rpk1/1p6/7b/2P3pp/BP1PK3/2P2P1P/8 b - - 3 45\n",
            "Index of closest historical FEN: 1000\n",
            "Suggested historical move: Kf6\n",
            "\n",
            "Original FEN: r1bqr1k1/ppp2ppp/1nnp4/6b1/2PP4/1PN1BN1P/P4PP1/2RQKB1R w K - 1 12\n",
            "Index of closest historical FEN: 10000\n",
            "Suggested historical move: Nxg5\n",
            "\n",
            "Original FEN: 2b3r1/pp6/2p2k2/2Pp1pN1/1P1RnP1r/P4R1P/6B1/6K1 b - - 0 38\n",
            "Index of closest historical FEN: 86860\n",
            "Suggested historical move: Rh5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d76948c"
      },
      "source": [
        "## Analyze rag effectiveness\n",
        "\n",
        "### Subtask:\n",
        "Retry: Evaluate if the current RAG approach (hashing FENs) is providing relevant historical moves. Consider alternative embedding methods for chess positions if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff7a603b"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt showed that simple hashing of FENs is ineffective due to collisions. I need to find an alternative way to represent chess positions as numerical vectors (embeddings) that can be used with FAISS. I will implement a simple handcrafted feature-based embedding as a starting point. This involves counting pieces and their positions. I will then update the FAISS index and the RAG function to use this new embedding. Finally, I will perform a manual evaluation to check the relevance of the retrieved historical moves.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9546f73",
        "outputId": "1808d2e7-a52d-427b-aba0-dbd03cad0dd4"
      },
      "source": [
        "import chess\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "def board_to_vector(board):\n",
        "    \"\"\"Converts a chess board state to a numerical vector (embedding).\"\"\"\n",
        "    vector = np.zeros(768, dtype=np.float32) # 64 squares * 12 piece types = 768 features\n",
        "    piece_map = {\n",
        "        chess.PAWN: 0, chess.KNIGHT: 1, chess.BISHOP: 2,\n",
        "        chess.ROOK: 3, chess.QUEEN: 4, chess.KING: 5\n",
        "    }\n",
        "\n",
        "    for square in chess.SQUARES:\n",
        "        piece = board.piece_at(square)\n",
        "        if piece:\n",
        "            color_offset = 0 if piece.color == chess.WHITE else 6 # White pieces first 6, Black next 6\n",
        "            piece_index = piece_map[piece.piece_type] + color_offset\n",
        "            vector[square * 12 + piece_index] = 1 # One-hot encoding for piece on square\n",
        "\n",
        "    # Add turn as a feature\n",
        "    vector = np.append(vector, 1.0 if board.turn == chess.WHITE else 0.0) # 769 features\n",
        "\n",
        "    # Add castling rights\n",
        "    vector = np.append(vector, 1.0 if board.has_kingside_castling_rights(chess.WHITE) else 0.0) # 770\n",
        "    vector = np.append(vector, 1.0 if board.has_queenside_castling_rights(chess.WHITE) else 0.0) # 771\n",
        "    vector = np.append(vector, 1.0 if board.has_kingside_castling_rights(chess.BLACK) else 0.0) # 772\n",
        "    vector = np.append(vector, 1.0 if board.has_queenside_castling_rights(chess.BLACK) else 0.0) # 773\n",
        "\n",
        "    # Add en passant square\n",
        "    en_passant_square = board.ep_square\n",
        "    if en_passant_square is not None:\n",
        "        vector = np.append(vector, en_passant_square + 1) # 774 (0 if no en passant)\n",
        "    else:\n",
        "        vector = np.append(vector, 0.0) # 774\n",
        "\n",
        "    # Add halfmove clock (fifty-move rule)\n",
        "    vector = np.append(vector, board.halfmove_clock) # 775\n",
        "\n",
        "    # Add fullmove number\n",
        "    vector = np.append(vector, board.fullmove_number) # 776 features in total\n",
        "\n",
        "\n",
        "    return vector\n",
        "\n",
        "# Generate embeddings for all FENs\n",
        "fen_embeddings = np.array([board_to_vector(chess.Board(fen)) for fen in fens])\n",
        "\n",
        "# Create a new FAISS index using the embeddings\n",
        "embedding_dim = fen_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "index.add(fen_embeddings)\n",
        "\n",
        "print(f\"Created FAISS index with {index.ntotal} embeddings of dimension {embedding_dim}.\")\n",
        "\n",
        "def suggest_move_by_rag(current_fen):\n",
        "    \"\"\"Suggests a move based on the most similar historical position found via RAG.\"\"\"\n",
        "    current_board = chess.Board(current_fen)\n",
        "    query_embedding = board_to_vector(current_board).reshape(1, -1) # Reshape for FAISS\n",
        "\n",
        "    D, I = index.search(query_embedding, 1)\n",
        "    closest_index = I[0][0]\n",
        "    return move_dict[closest_index]\n",
        "\n",
        "# Manual Evaluation (Repeat the evaluation from the previous step with new RAG)\n",
        "print(\"\\n--- Evaluating RAG Effectiveness with New Embeddings ---\")\n",
        "\n",
        "# Select a few diverse FENs from the list (using the same indices as before for comparison)\n",
        "selected_indices = [0, 100, 1000, 10000, len(fens) - 1]\n",
        "selected_fens = [fens[i] for i in selected_indices]\n",
        "\n",
        "for original_fen in selected_fens:\n",
        "    print(f\"\\nOriginal FEN: {original_fen}\")\n",
        "\n",
        "    # Get embedding and search index\n",
        "    current_board = chess.Board(original_fen)\n",
        "    query_embedding = board_to_vector(current_board).reshape(1, -1)\n",
        "    D, I = index.search(query_embedding, 1)\n",
        "    closest_index = I[0][0]\n",
        "\n",
        "    # Retrieve historical move\n",
        "    suggested_historical_move = move_dict[closest_index]\n",
        "\n",
        "    # Retrieve the FEN of the closest historical position for better evaluation\n",
        "    closest_fen = fens[closest_index]\n",
        "\n",
        "\n",
        "    print(f\"Index of closest historical FEN: {closest_index}\")\n",
        "    print(f\"Closest historical FEN: {closest_fen}\")\n",
        "    print(f\"Suggested historical move from historical FEN: {suggested_historical_move}\")\n",
        "\n",
        "    # Manual Inspection Guidance:\n",
        "    # Compare the Original FEN with the Closest historical FEN.\n",
        "    # Are they similar? Then look at the Suggested historical move.\n",
        "    # Does this move make sense in the context of both the original and closest historical FEN?\n",
        "    # This manual check helps confirm if the new embedding method is effective\n",
        "    # at finding truly *similar* historical positions and if the suggested move is relevant.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created FAISS index with 86861 embeddings of dimension 776.\n",
            "\n",
            "--- Evaluating RAG Effectiveness with New Embeddings ---\n",
            "\n",
            "Original FEN: rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
            "Index of closest historical FEN: 0\n",
            "Closest historical FEN: rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
            "Suggested historical move from historical FEN: d4\n",
            "\n",
            "Original FEN: 2r2bk1/4nppp/4p3/p2pP3/n1r4P/PRP1B1P1/2N2P2/RN3K2 w - - 4 28\n",
            "Index of closest historical FEN: 100\n",
            "Closest historical FEN: 2r2bk1/4nppp/4p3/p2pP3/n1r4P/PRP1B1P1/2N2P2/RN3K2 w - - 4 28\n",
            "Suggested historical move from historical FEN: Bd4\n",
            "\n",
            "Original FEN: 2r5/p1p1Rpk1/1p6/7b/2P3pp/BP1PK3/2P2P1P/8 b - - 3 45\n",
            "Index of closest historical FEN: 1000\n",
            "Closest historical FEN: 2r5/p1p1Rpk1/1p6/7b/2P3pp/BP1PK3/2P2P1P/8 b - - 3 45\n",
            "Suggested historical move from historical FEN: Kf6\n",
            "\n",
            "Original FEN: r1bqr1k1/ppp2ppp/1nnp4/6b1/2PP4/1PN1BN1P/P4PP1/2RQKB1R w K - 1 12\n",
            "Index of closest historical FEN: 10000\n",
            "Closest historical FEN: r1bqr1k1/ppp2ppp/1nnp4/6b1/2PP4/1PN1BN1P/P4PP1/2RQKB1R w K - 1 12\n",
            "Suggested historical move from historical FEN: Nxg5\n",
            "\n",
            "Original FEN: 2b3r1/pp6/2p2k2/2Pp1pN1/1P1RnP1r/P4R1P/6B1/6K1 b - - 0 38\n",
            "Index of closest historical FEN: 86860\n",
            "Closest historical FEN: 2b3r1/pp6/2p2k2/2Pp1pN1/1P1RnP1r/P4R1P/6B1/6K1 b - - 0 38\n",
            "Suggested historical move from historical FEN: Rh5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0af40248"
      },
      "source": [
        "## Improve prompt engineering\n",
        "\n",
        "### Subtask:\n",
        "Experiment with different prompt structures and phrasings to better guide the LLM towards selecting legal and potentially more strategic moves from the provided list.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f23d174"
      },
      "source": [
        "**Reasoning**:\n",
        "I will analyze the current prompt structure and create a new function with an alternative prompt structure that places legal moves earlier and emphasizes selecting only from the list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "7a6297b6",
        "outputId": "f6d6a1ba-3248-4897-ac13-d4663caba830"
      },
      "source": [
        "import chess\n",
        "\n",
        "def build_prompt_with_history_v1(board, historical_move):\n",
        "    \"\"\"Builds a prompt for the LLM with historical context.\"\"\"\n",
        "    fen = board.fen()\n",
        "\n",
        "    # Build human-readable move history (SAN format, e.g., 1. e4 c5)\n",
        "    move_history = []\n",
        "    temp_board = chess.Board()\n",
        "    for move in board.move_stack:\n",
        "        move_history.append(temp_board.san(move))\n",
        "        temp_board.push(move)\n",
        "\n",
        "    numbered_history = \"\"\n",
        "    for i in range(0, len(move_history), 2):\n",
        "        turn = i // 2 + 1\n",
        "        white = move_history[i]\n",
        "        black = move_history[i+1] if i + 1 < len(move_history) else \"\"\n",
        "        numbered_history += f\"{turn}. {white} {black} \"\n",
        "\n",
        "    # Get legal moves in long algebraic notation\n",
        "    legal_moves_uci = [move.uci() for move in board.legal_moves]\n",
        "    legal_moves_str = \", \".join(legal_moves_uci)\n",
        "\n",
        "    # Alternative prompt structure: Legal moves first, stronger emphasis\n",
        "    return f\"\"\"You are a chess AI assistant.\n",
        "\n",
        "Here are the legal moves in the current position: {legal_moves_str}\n",
        "\n",
        "Please select ONLY one move from this list.\n",
        "\n",
        "Game so far:\n",
        "{numbered_history.strip()}\n",
        "\n",
        "Current board position (FEN):\n",
        "{fen}\n",
        "\n",
        "A similar historical move was: {historical_move}\n",
        "\n",
        "It is {'White' if board.turn else 'Black'} to play.\n",
        "\n",
        "Your response MUST be ONLY the selected legal move in **long algebraic notation** (e.g., \"e2e4\", \"g1f3\", \"c1d3\"). Do NOT include any other text, explanation, or formatting.\n",
        "\n",
        "Move:\"\"\"\n",
        "\n",
        "# Keep the original prompt function for potential comparison (optional)\n",
        "# def build_prompt_with_history_original(board, historical_move):\n",
        "#     fen = board.fen()\n",
        "#     move_history = []\n",
        "#     temp_board = chess.Board()\n",
        "#     for move in board.move_stack:\n",
        "#         move_history.append(temp_board.san(move))\n",
        "#         temp_board.push(move)\n",
        "#     numbered_history = \"\"\n",
        "#     for i in range(0, len(move_history), 2):\n",
        "#         turn = i // 2 + 1\n",
        "#         white = move_history[i]\n",
        "#         black = move_history[i+1] if i + 1 < len(move_history) else \"\"\n",
        "#         numbered_history += f\"{turn}. {white} {black} \"\n",
        "#     legal_moves_uci = [move.uci() for move in board.legal_moves]\n",
        "#     legal_moves_str = \", \".join(legal_moves_uci)\n",
        "#     return f\"\"\"You are a chess AI assistant.\n",
        "\n",
        "# Game so far:\n",
        "# {numbered_history.strip()}\n",
        "\n",
        "# Current board position (FEN):\n",
        "# {fen}\n",
        "\n",
        "# A similar historical move was: {historical_move}\n",
        "\n",
        "# It is {'White' if board.turn else 'Black'} to play.\n",
        "\n",
        "# The legal moves in this position are: {legal_moves_str}\n",
        "\n",
        "# Please respond with ONLY the next legal move from the list provided above in **long algebraic notation** like \"e2e4\", \"g1f3\", or \"c1d3\".\n",
        "\n",
        "# Do NOT explain. Only output the move.\n",
        "\n",
        "# Move:\"\"\"\n",
        "\n",
        "\n",
        "# Initialize board\n",
        "board = chess.Board()\n",
        "\n",
        "# Main loop: Player vs AI\n",
        "print(\"\\n--- Starting New Game with Updated Prompt ---\")\n",
        "while not board.is_game_over():\n",
        "    print(\"\\nÂΩìÂâçÊ£ãÁõò:\")\n",
        "    print(board)\n",
        "\n",
        "    # Player move\n",
        "    try:\n",
        "        player_move = input(\"\\n‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): \").strip()\n",
        "        move = chess.Move.from_uci(player_move)\n",
        "        if move in board.legal_moves:\n",
        "            board.push(move)\n",
        "        else:\n",
        "            print(\"‚ùå ÈùûÊ≥ïËµ∞Ê≥ï:\", player_move)\n",
        "            continue\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå ËæìÂÖ•ÈîôËØØ:\", e)\n",
        "        continue\n",
        "\n",
        "    # Check if game is over after player's move\n",
        "    if board.is_game_over():\n",
        "        print(\"üèÅ Ê∏∏ÊàèÁªìÊùüÔºÅ\")\n",
        "        break\n",
        "\n",
        "    # AI move\n",
        "    fen = board.fen()\n",
        "    # Use the updated suggest_move_by_rag with the new embedding\n",
        "    historical_move = suggest_move_by_rag(fen)\n",
        "\n",
        "    # Get AI suggestion using the new prompt structure\n",
        "    prompt = build_prompt_with_history_v1(board, historical_move) # Use the new prompt function\n",
        "    suggestion = get_move_from_llm(prompt).strip().split()[0]\n",
        "    print(\"\\nü§ñ AIÂª∫ËÆÆËµ∞Ê≥ï:\", suggestion)\n",
        "\n",
        "    # Validate AI move and push if legal, otherwise pick a random legal move\n",
        "    try:\n",
        "        ai_move = chess.Move.from_uci(suggestion)\n",
        "        if ai_move in board.legal_moves:\n",
        "            board.push(ai_move)\n",
        "        else:\n",
        "            print(\"‚ùå AI Âª∫ËÆÆÈùûÊ≥ïËµ∞Ê≥ï:\", suggestion, \". Choosing a random legal move.\")\n",
        "            legal_moves = list(board.legal_moves)\n",
        "            if legal_moves:\n",
        "                chosen_move = random.choice(legal_moves)\n",
        "                print(f\"ü§ñ AI makes legal move: {chosen_move.uci()}\")\n",
        "                board.push(chosen_move)\n",
        "            else:\n",
        "                print(\"ü§∑ No legal moves available for AI.\")\n",
        "                break # Should not happen in a standard game\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå AI ËæìÂá∫Ê†ºÂºèÈîôËØØ:\", suggestion, \"| ÈîôËØØ:\", e, \". Choosing a random legal move.\")\n",
        "        legal_moves = list(board.legal_moves)\n",
        "        if legal_moves:\n",
        "            chosen_move = random.choice(legal_moves)\n",
        "            print(f\"ü§ñ AI makes legal move: {chosen_move.uci()}\")\n",
        "            board.push(chosen_move)\n",
        "        else:\n",
        "            print(\"ü§∑ No legal moves available for AI.\")\n",
        "            break # Should not happen in a standard game\n",
        "\n",
        "\n",
        "# Game over\n",
        "print(\"\\nüèÅ Ê∏∏ÊàèÁªìÊùüÔºÅÁªìÊûú:\", board.result())\n",
        "print(board)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting New Game with Updated Prompt ---\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            "P P P P P P P P\n",
            "R N B Q K B N R\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): e2e4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 9 prefix-match hit, remaining 246 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   20660.81 ms\n",
            "llama_perf_context_print: prompt eval time =   20072.91 ms /   246 tokens (   81.60 ms per token,    12.26 tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   20076.79 ms /   247 tokens\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-28-37445785.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# Get AI suggestion using the new prompt structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_prompt_with_history_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistorical_move\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Use the new prompt function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0msuggestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_move_from_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nü§ñ AIÂª∫ËÆÆËµ∞Ê≥ï:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuggestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6796d79f"
      },
      "source": [
        "**Reasoning**:\n",
        "The AI output is causing an `IndexError` because `split()[0]` is being called on an empty string or a string with no spaces. This likely means the LLM is not returning the move in the expected format. I will modify the `get_move_from_llm` function to be more robust in parsing the LLM's output and handle cases where it doesn't return a move directly, potentially by looking for move patterns or defaulting to the historical move if the LLM output is unparseable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fZk4a3rUB9uV",
        "outputId": "1fc4868d-6007-483a-fe67-a2293fa15725"
      },
      "source": [
        "import chess\n",
        "import random\n",
        "\n",
        "def build_prompt_with_history_v1(board, historical_move):\n",
        "    \"\"\"Builds a prompt for the LLM with historical context.\"\"\"\n",
        "    fen = board.fen()\n",
        "\n",
        "    # Build human-readable move history (SAN format, e.g., 1. e4 c5)\n",
        "    move_history = []\n",
        "    temp_board = chess.Board()\n",
        "    for move in board.move_stack:\n",
        "        move_history.append(temp_board.san(move))\n",
        "        temp_board.push(move)\n",
        "\n",
        "    numbered_history = \"\"\n",
        "    for i in range(0, len(move_history), 2):\n",
        "        turn = i // 2 + 1\n",
        "        white = move_history[i]\n",
        "        black = move_history[i+1] if i + 1 < len(move_history) else \"\"\n",
        "        numbered_history += f\"{turn}. {white} {black} \"\n",
        "\n",
        "    # Get legal moves in long algebraic notation\n",
        "    legal_moves_uci = [move.uci() for move in board.legal_moves]\n",
        "    legal_moves_str = \", \".join(legal_moves_uci)\n",
        "\n",
        "    # Alternative prompt structure: Legal moves first, stronger emphasis\n",
        "    return f\"\"\"You are a chess AI assistant.\n",
        "\n",
        "Here are the legal moves in the current position: {legal_moves_str}\n",
        "\n",
        "Please select ONLY one move from this list.\n",
        "\n",
        "Game so far:\n",
        "{numbered_history.strip()}\n",
        "\n",
        "Current board position (FEN):\n",
        "{fen}\n",
        "\n",
        "A similar historical move was: {historical_move}\n",
        "\n",
        "It is {'White' if board.turn else 'Black'} to play.\n",
        "\n",
        "Your response MUST be ONLY the selected legal move in **long algebraic notation** (e.g., \"e2e4\", \"g1f3\", \"c1d3\"). Do NOT include any other text, explanation, or formatting.\n",
        "\n",
        "Move:\"\"\"\n",
        "\n",
        "def get_move_from_llm(prompt):\n",
        "    \"\"\"Gets a move suggestion from the LLM and attempts to parse it.\"\"\"\n",
        "    output = llm(prompt, max_tokens=128) # Increased max_tokens\n",
        "    text_output = output[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "    # Attempt to parse the output to find a legal move\n",
        "    legal_moves_uci = [move.uci() for move in board.legal_moves]\n",
        "\n",
        "    # Simple split and check first word\n",
        "    potential_move = text_output.split()[0] if text_output else \"\"\n",
        "    if potential_move in legal_moves_uci:\n",
        "        return potential_move\n",
        "\n",
        "    # If the first word isn't a legal move, try to find any legal move in the output\n",
        "    for move_uci in legal_moves_uci:\n",
        "        if move_uci in text_output:\n",
        "            return move_uci\n",
        "\n",
        "    # If no legal move found in the output, return a placeholder or handle as needed\n",
        "    # For now, let's return None and handle it in the main loop\n",
        "    return None\n",
        "\n",
        "\n",
        "# Keep the original prompt function for potential comparison (optional)\n",
        "# def build_prompt_with_history_original(board, historical_move):\n",
        "#     fen = board.fen()\n",
        "#     move_history = []\n",
        "#     temp_board = chess.Board()\n",
        "#     for move in board.move_stack:\n",
        "#         move_history.append(temp_board.san(move))\n",
        "#         temp_board.push(move)\n",
        "#     numbered_history = \"\"\n",
        "#     for i in range(0, len(move_history), 2):\n",
        "#         turn = i // 2 + 1\n",
        "#         white = move_history[i]\n",
        "#         black = move_history[i+1] if i + 1 < len(move_history) else \"\"\n",
        "#         numbered_history += f\"{turn}. {white} {black} \"\n",
        "#     legal_moves_uci = [move.uci() for move in board.legal_moves]\n",
        "#     legal_moves_str = \", \".join(legal_moves_uci)\n",
        "#     return f\"\"\"You are a chess AI assistant.\n",
        "\n",
        "# Game so far:\n",
        "# {numbered_history.strip()}\n",
        "\n",
        "# Current board position (FEN):\n",
        "# {fen}\n",
        "\n",
        "# A similar historical move was: {historical_move}\n",
        "\n",
        "# It is {'White' if board.turn else 'Black'} to play.\n",
        "\n",
        "# The legal moves in this position are: {legal_moves_str}\n",
        "\n",
        "# Please respond with ONLY the next legal move from the list provided above in **long algebraic notation** like \"e2e4\", \"g1f3\", or \"c1d3\".\n",
        "\n",
        "# Do NOT explain. Only output the move.\n",
        "\n",
        "# Move:\"\"\"\n",
        "\n",
        "\n",
        "# Initialize board\n",
        "board = chess.Board()\n",
        "\n",
        "# Main loop: Player vs AI\n",
        "print(\"\\n--- Starting New Game with Updated Prompt ---\")\n",
        "while not board.is_game_over():\n",
        "    print(\"\\nÂΩìÂâçÊ£ãÁõò:\")\n",
        "    print(board)\n",
        "\n",
        "    # Player move\n",
        "    try:\n",
        "        player_move = input(\"\\n‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): \").strip()\n",
        "        move = chess.Move.from_uci(player_move)\n",
        "        if move in board.legal_moves:\n",
        "            board.push(move)\n",
        "        else:\n",
        "            print(\"‚ùå ÈùûÊ≥ïËµ∞Ê≥ï:\", player_move)\n",
        "            continue\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå ËæìÂÖ•ÈîôËØØ:\", e)\n",
        "        continue\n",
        "\n",
        "    # Check if game is over after player's move\n",
        "    if board.is_game_over():\n",
        "        print(\"üèÅ Ê∏∏ÊàèÁªìÊùüÔºÅ\")\n",
        "        break\n",
        "\n",
        "    # AI move\n",
        "    fen = board.fen()\n",
        "    # Use the updated suggest_move_by_rag with the new embedding\n",
        "    historical_move = suggest_move_by_rag(fen)\n",
        "\n",
        "    # Get AI suggestion using the new prompt structure\n",
        "    prompt = build_prompt_with_history_v1(board, historical_move) # Use the new prompt function\n",
        "    suggestion = get_move_from_llm(prompt) # Get suggestion from the modified function\n",
        "\n",
        "    print(\"\\nü§ñ AIÂª∫ËÆÆËµ∞Ê≥ï:\", suggestion)\n",
        "\n",
        "    # Validate AI move and push if legal, otherwise pick a random legal move\n",
        "    try:\n",
        "        if suggestion and chess.Move.from_uci(suggestion) in board.legal_moves:\n",
        "            ai_move = chess.Move.from_uci(suggestion)\n",
        "            board.push(ai_move)\n",
        "        else:\n",
        "            print(\"‚ùå AI Âª∫ËÆÆÈùûÊ≥ïËµ∞Ê≥ïÊàñËæìÂá∫Êó†Ê≥ïËß£Êûê:\", suggestion, \". Choosing a random legal move.\")\n",
        "            legal_moves = list(board.legal_moves)\n",
        "            if legal_moves:\n",
        "                chosen_move = random.choice(legal_moves)\n",
        "                print(f\"ü§ñ AI makes legal move: {chosen_move.uci()}\")\n",
        "                board.push(chosen_move)\n",
        "            else:\n",
        "                print(\"ü§∑ No legal moves available for AI.\")\n",
        "                break # Should not happen in a standard game\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå AI ËæìÂá∫Ê†ºÂºèÈîôËØØÊàñËß£ÊûêÂºÇÂ∏∏:\", suggestion, \"| ÈîôËØØ:\", e, \". Choosing a random legal move.\")\n",
        "        legal_moves = list(board.legal_moves)\n",
        "        if legal_moves:\n",
        "            chosen_move = random.choice(legal_moves)\n",
        "            print(f\"ü§ñ AI makes legal move: {chosen_move.uci()}\")\n",
        "            board.push(chosen_move)\n",
        "        else:\n",
        "            print(\"ü§∑ No legal moves available for AI.\")\n",
        "            break # Should not happen in a standard game\n",
        "\n",
        "\n",
        "# Game over\n",
        "print(\"\\nüèÅ Ê∏∏ÊàèÁªìÊùüÔºÅÁªìÊûú:\", board.result())\n",
        "print(board)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting New Game with Updated Prompt ---\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            "P P P P P P P P\n",
            "R N B Q K B N R\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): e2e4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 254 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   20660.81 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =     207.91 ms /     1 runs   (  207.91 ms per token,     4.81 tokens per second)\n",
            "llama_perf_context_print:       total time =     210.85 ms /     2 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ü§ñ AIÂª∫ËÆÆËµ∞Ê≥ï: None\n",
            "‚ùå AI Âª∫ËÆÆÈùûÊ≥ïËµ∞Ê≥ïÊàñËæìÂá∫Êó†Ê≥ïËß£Êûê: None . Choosing a random legal move.\n",
            "ü§ñ AI makes legal move: a7a6\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b n r\n",
            ". p p p p p p p\n",
            "p . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . P . . .\n",
            ". . . . . . . .\n",
            "P P P P . P P P\n",
            "R N B Q K B N R\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): c1d3\n",
            "‚ùå ÈùûÊ≥ïËµ∞Ê≥ï: c1d3\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b n r\n",
            ". p p p p p p p\n",
            "p . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . P . . .\n",
            ". . . . . . . .\n",
            "P P P P . P P P\n",
            "R N B Q K B N R\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): c1d4\n",
            "‚ùå ÈùûÊ≥ïËµ∞Ê≥ï: c1d4\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b n r\n",
            ". p p p p p p p\n",
            "p . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . P . . .\n",
            ". . . . . . . .\n",
            "P P P P . P P P\n",
            "R N B Q K B N R\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): c1d5\n",
            "‚ùå ÈùûÊ≥ïËµ∞Ê≥ï: c1d5\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b n r\n",
            ". p p p p p p p\n",
            "p . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . P . . .\n",
            ". . . . . . . .\n",
            "P P P P . P P P\n",
            "R N B Q K B N R\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): c1d3\n",
            "‚ùå ÈùûÊ≥ïËµ∞Ê≥ï: c1d3\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b n r\n",
            ". p p p p p p p\n",
            "p . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . P . . .\n",
            ". . . . . . . .\n",
            "P P P P . P P P\n",
            "R N B Q K B N R\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): b1c3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 34 prefix-match hit, remaining 227 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   20660.81 ms\n",
            "llama_perf_context_print: prompt eval time =   20294.55 ms /   227 tokens (   89.40 ms per token,    11.19 tokens per second)\n",
            "llama_perf_context_print:        eval time =     408.05 ms /     2 runs   (  204.03 ms per token,     4.90 tokens per second)\n",
            "llama_perf_context_print:       total time =   20712.24 ms /   229 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ü§ñ AIÂª∫ËÆÆËµ∞Ê≥ï: None\n",
            "‚ùå AI Âª∫ËÆÆÈùûÊ≥ïËµ∞Ê≥ïÊàñËæìÂá∫Êó†Ê≥ïËß£Êûê: None . Choosing a random legal move.\n",
            "ü§ñ AI makes legal move: g8h6\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b . r\n",
            ". p p p p p p p\n",
            "p . . . . . . n\n",
            ". . . . . . . .\n",
            ". . . . P . . .\n",
            ". . N . . . . .\n",
            "P P P P . P P P\n",
            "R . B Q K B N R\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): d3e5\n",
            "‚ùå ÈùûÊ≥ïËµ∞Ê≥ï: d3e5\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b . r\n",
            ". p p p p p p p\n",
            "p . . . . . . n\n",
            ". . . . . . . .\n",
            ". . . . P . . .\n",
            ". . N . . . . .\n",
            "P P P P . P P P\n",
            "R . B Q K B N R\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): c3d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 19 prefix-match hit, remaining 246 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   20660.81 ms\n",
            "llama_perf_context_print: prompt eval time =   20014.44 ms /   246 tokens (   81.36 ms per token,    12.29 tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   20018.15 ms /   247 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ AIÂª∫ËÆÆËµ∞Ê≥ï: None\n",
            "‚ùå AI Âª∫ËÆÆÈùûÊ≥ïËµ∞Ê≥ïÊàñËæìÂá∫Êó†Ê≥ïËß£Êûê: None . Choosing a random legal move.\n",
            "ü§ñ AI makes legal move: c7c5\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "r n b q k b . r\n",
            ". p . p p p p p\n",
            "p . . . . . . n\n",
            ". . p N . . . .\n",
            ". . . . P . . .\n",
            ". . . . . . . .\n",
            "P P P P . P P P\n",
            "R . B Q K B N R\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-29-3628357512.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# Player move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mplayer_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n‰Ω†ÁöÑËµ∞Ê≥ï (long algebraic Ê†ºÂºèÔºåÂ¶Ç e2e4): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_uci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer_move\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegal_moves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "import random\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# ÂàùÂßãÂåñÊ®°Âûã\n",
        "llm = Llama(\n",
        "    model_path=\"./gemma-2b-it.Q4_K_M.gguf\",\n",
        "    n_ctx=1024,\n",
        "    n_threads=4,\n",
        "    n_gpu_layers=0,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "def print_board(board):\n",
        "    print(\"\\nÂΩìÂâçÊ£ãÁõò:\")\n",
        "    print(board.unicode(borders=True))\n",
        "    print()\n",
        "\n",
        "def is_valid_move(move_str, board):\n",
        "    try:\n",
        "        move = chess.Move.from_uci(move_str)\n",
        "        return move in board.legal_moves\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def format_chat_prompt(messages):\n",
        "    prompt = \"<bos>\"\n",
        "    for i, m in enumerate(messages):\n",
        "        role = \"user\" if m[\"role\"] == \"user\" else \"model\"\n",
        "        prompt += f\"<start_of_turn>{role}\\n{m['content'].strip()}<end_of_turn>\\n\"\n",
        "    prompt += \"<start_of_turn>model\\n\"\n",
        "    return prompt\n",
        "\n",
        "def query_ai_move(board, history):\n",
        "    messages = [{\"role\": \"user\", \"content\": history}]\n",
        "    prompt = format_chat_prompt(messages)\n",
        "\n",
        "    response = llm.create_completion(\n",
        "        prompt=prompt,\n",
        "        max_tokens=8,\n",
        "        temperature=0.7,\n",
        "        stop=[\"<end_of_turn>\"],\n",
        "    )\n",
        "    text = response[\"choices\"][0][\"text\"].strip().split()[0].lower()\n",
        "    return text\n",
        "\n",
        "def get_random_move(board):\n",
        "    return random.choice(list(board.legal_moves)).uci()\n",
        "\n",
        "# ‰∏ªÁ®ãÂ∫è\n",
        "board = chess.Board()\n",
        "print(\"‚ôüÔ∏è Êñ∞Ê£ãÂ±ÄÂºÄÂßãÔºå‰∫∫Á±ª vs Gemma AI\")\n",
        "print_board(board)\n",
        "\n",
        "history = \"\"\n",
        "\n",
        "while not board.is_game_over():\n",
        "    user_move = input(\"‰Ω†ÁöÑËµ∞Ê≥ï (Â¶Ç e2e4): \").strip().lower()\n",
        "    if not is_valid_move(user_move, board):\n",
        "        print(\"‚ö†Ô∏è ÈùûÊ≥ïËµ∞Ê≥ïÔºåËØ∑ÈáçËØï\")\n",
        "        continue\n",
        "    board.push_uci(user_move)\n",
        "    history += f\"{user_move} \"\n",
        "\n",
        "    print_board(board)\n",
        "\n",
        "    ai_move = query_ai_move(board, history)\n",
        "\n",
        "    if not is_valid_move(ai_move, board):\n",
        "        print(f\"‚ö†Ô∏è AI ËæìÂá∫ÈùûÊ≥ïÂÜÖÂÆπ: '{ai_move}'\")\n",
        "        ai_move = get_random_move(board)\n",
        "        print(\"‚ö†Ô∏è AI ËæìÂá∫ÈùûÊ≥ïËµ∞Ê≥ïÔºå‰ΩøÁî®ÈöèÊú∫ÂêàÊ≥ïËµ∞Ê≥ï\")\n",
        "\n",
        "    print(f\"‚úÖ AI ÂÆûÈôÖËµ∞Ê≥ï: {ai_move}\")\n",
        "    board.push_uci(ai_move)\n",
        "    history += f\"{ai_move} \"\n",
        "    print_board(board)\n",
        "\n",
        "print(\"üèÅ Ê∏∏ÊàèÁªìÊùü\")\n",
        "print(\"ÊúÄÁªàÁªìÊûú:\", board.result())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nuFJfgOAyhfl",
        "outputId": "4643f043-fa3d-4f8e-eb53-316ae4b97a9b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_context: n_ctx_per_seq (1024) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ôüÔ∏è Êñ∞Ê£ãÂ±ÄÂºÄÂßãÔºå‰∫∫Á±ª vs Gemma AI\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "  -----------------\n",
            "8 |‚ôú|‚ôû|‚ôù|‚ôõ|‚ôö|‚ôù|‚ôû|‚ôú|\n",
            "  -----------------\n",
            "7 |‚ôü|‚ôü|‚ôü|‚ôü|‚ôü|‚ôü|‚ôü|‚ôü|\n",
            "  -----------------\n",
            "6 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "5 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "4 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "3 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "2 |‚ôô|‚ôô|‚ôô|‚ôô|‚ôô|‚ôô|‚ôô|‚ôô|\n",
            "  -----------------\n",
            "1 |‚ôñ|‚ôò|‚ôó|‚ôï|‚ôî|‚ôó|‚ôò|‚ôñ|\n",
            "  -----------------\n",
            "   a b c d e f g h\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (Â¶Ç e2e4): e2e4\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "  -----------------\n",
            "8 |‚ôú|‚ôû|‚ôù|‚ôõ|‚ôö|‚ôù|‚ôû|‚ôú|\n",
            "  -----------------\n",
            "7 |‚ôü|‚ôü|‚ôü|‚ôü|‚ôü|‚ôü|‚ôü|‚ôü|\n",
            "  -----------------\n",
            "6 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "5 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "4 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚ôô|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "3 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "2 |‚ôô|‚ôô|‚ôô|‚ôô|‚≠ò|‚ôô|‚ôô|‚ôô|\n",
            "  -----------------\n",
            "1 |‚ôñ|‚ôò|‚ôó|‚ôï|‚ôî|‚ôó|‚ôò|‚ôñ|\n",
            "  -----------------\n",
            "   a b c d e f g h\n",
            "\n",
            "‚ö†Ô∏è AI ËæìÂá∫ÈùûÊ≥ïÂÜÖÂÆπ: 'i'\n",
            "‚ö†Ô∏è AI ËæìÂá∫ÈùûÊ≥ïËµ∞Ê≥ïÔºå‰ΩøÁî®ÈöèÊú∫ÂêàÊ≥ïËµ∞Ê≥ï\n",
            "‚úÖ AI ÂÆûÈôÖËµ∞Ê≥ï: f7f5\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "  -----------------\n",
            "8 |‚ôú|‚ôû|‚ôù|‚ôõ|‚ôö|‚ôù|‚ôû|‚ôú|\n",
            "  -----------------\n",
            "7 |‚ôü|‚ôü|‚ôü|‚ôü|‚ôü|‚≠ò|‚ôü|‚ôü|\n",
            "  -----------------\n",
            "6 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "5 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚ôü|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "4 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚ôô|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "3 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "2 |‚ôô|‚ôô|‚ôô|‚ôô|‚≠ò|‚ôô|‚ôô|‚ôô|\n",
            "  -----------------\n",
            "1 |‚ôñ|‚ôò|‚ôó|‚ôï|‚ôî|‚ôó|‚ôò|‚ôñ|\n",
            "  -----------------\n",
            "   a b c d e f g h\n",
            "\n",
            "‰Ω†ÁöÑËµ∞Ê≥ï (Â¶Ç e2e4): b1c3\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "  -----------------\n",
            "8 |‚ôú|‚ôû|‚ôù|‚ôõ|‚ôö|‚ôù|‚ôû|‚ôú|\n",
            "  -----------------\n",
            "7 |‚ôü|‚ôü|‚ôü|‚ôü|‚ôü|‚≠ò|‚ôü|‚ôü|\n",
            "  -----------------\n",
            "6 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "5 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚ôü|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "4 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚ôô|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "3 |‚≠ò|‚≠ò|‚ôò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "2 |‚ôô|‚ôô|‚ôô|‚ôô|‚≠ò|‚ôô|‚ôô|‚ôô|\n",
            "  -----------------\n",
            "1 |‚ôñ|‚≠ò|‚ôó|‚ôï|‚ôî|‚ôó|‚ôò|‚ôñ|\n",
            "  -----------------\n",
            "   a b c d e f g h\n",
            "\n",
            "‚ö†Ô∏è AI ËæìÂá∫ÈùûÊ≥ïÂÜÖÂÆπ: 'sure!'\n",
            "‚ö†Ô∏è AI ËæìÂá∫ÈùûÊ≥ïËµ∞Ê≥ïÔºå‰ΩøÁî®ÈöèÊú∫ÂêàÊ≥ïËµ∞Ê≥ï\n",
            "‚úÖ AI ÂÆûÈôÖËµ∞Ê≥ï: c7c6\n",
            "\n",
            "ÂΩìÂâçÊ£ãÁõò:\n",
            "  -----------------\n",
            "8 |‚ôú|‚ôû|‚ôù|‚ôõ|‚ôö|‚ôù|‚ôû|‚ôú|\n",
            "  -----------------\n",
            "7 |‚ôü|‚ôü|‚≠ò|‚ôü|‚ôü|‚≠ò|‚ôü|‚ôü|\n",
            "  -----------------\n",
            "6 |‚≠ò|‚≠ò|‚ôü|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "5 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚ôü|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "4 |‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚ôô|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "3 |‚≠ò|‚≠ò|‚ôò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|‚≠ò|\n",
            "  -----------------\n",
            "2 |‚ôô|‚ôô|‚ôô|‚ôô|‚≠ò|‚ôô|‚ôô|‚ôô|\n",
            "  -----------------\n",
            "1 |‚ôñ|‚≠ò|‚ôó|‚ôï|‚ôî|‚ôó|‚ôò|‚ôñ|\n",
            "  -----------------\n",
            "   a b c d e f g h\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-18-1966335578.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_game_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0muser_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‰Ω†ÁöÑËµ∞Ê≥ï (Â¶Ç e2e4): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_valid_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_move\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚ö†Ô∏è ÈùûÊ≥ïËµ∞Ê≥ïÔºåËØ∑ÈáçËØï\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}