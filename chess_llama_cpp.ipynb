{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEPX3g9benI1W0mZInD23D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/durfred/my-first-binder/blob/main/chess_llama_cpp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Gemini GGUF (example: Gemini-1.5-mini Q4_0 GGUF)\n",
        "!wget -O gemini.gguf https://huggingface.co/bartowski/gemma-2-2b-it-abliterated-GGUF/resolve/main/gemma-2-2b-it-abliterated-IQ4_XS.gguf"
      ],
      "metadata": {
        "id": "VA3Mluhyqk3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python\n",
        "\n"
      ],
      "metadata": {
        "id": "H6An0jOPqvzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Clean Gemini output\n",
        "def clean_move_string(raw):\n",
        "    move = raw.strip().lower()\n",
        "    move = re.sub(r'[^a-z0-9=]+', '', move)  # Remove non-uci/san characters (like **, .)\n",
        "    return move\n",
        "\n",
        "def ai_move_with_gemini(board):\n",
        "    prompt = f\"\"\"\n",
        "You are a chess engine. Only respond with a legal move in **UCI format** (e.g., e2e4, g1f3). Do not explain. No SAN like 'e4'. Just the move.\n",
        "\n",
        "FEN: {board.fen()}\n",
        "\n",
        "Move:\"\"\"\n",
        "\n",
        "    output = llm(prompt, max_tokens=16, temperature=0.2, stop=[\"\\n\"])\n",
        "    move_str = output['choices'][0]['text']\n",
        "    print(f\"Gemini raw output: {move_str}\")\n",
        "\n",
        "    move_str_clean = clean_move_string(move_str)\n",
        "\n",
        "    # Try UCI first\n",
        "    try:\n",
        "        move = chess.Move.from_uci(move_str)\n",
        "        if move in board.legal_moves:\n",
        "            return move\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Try SAN fallback with title-casing (e.g., d3 -> D3)\n",
        "    try:\n",
        "        move_str_san = move_str.strip().title()\n",
        "        move = board.parse_san(move_str_san)\n",
        "        if move in board.legal_moves:\n",
        "            print(f\"✔ Interpreted SAN '{move_str_san}' as UCI '{move.uci()}'\")\n",
        "            return move\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to interpret move: {e}\")\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "KyUhZPaJtYVr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_board = chess.Board()\n",
        "# print(\"FEN:\", test_board.fen())\n",
        "# print(\"Gemini says:\", ai_move_with_gemini(test_board))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uGVcgA2teS_",
        "outputId": "69d0cd1f-4114-44cb-9390-89bdcad9c7a4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FEN: rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 6 prefix-match hit, remaining 88 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   14716.68 ms\n",
            "llama_perf_context_print: prompt eval time =   15808.76 ms /    88 tokens (  179.65 ms per token,     5.57 tokens per second)\n",
            "llama_perf_context_print:        eval time =     310.75 ms /     1 runs   (  310.75 ms per token,     3.22 tokens per second)\n",
            "llama_perf_context_print:       total time =   16126.06 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini raw output: \n",
            "❌ Failed to interpret move\n",
            "Gemini says: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ImhlvXsetvVn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}